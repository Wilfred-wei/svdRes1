# ForgeLens SVD æ­£äº¤çº¦æŸä¿®æ”¹æ€»ç»“

## ğŸ“‹ æ¦‚è¿°

æœ¬ä¿®æ”¹å°† **Effort è®ºæ–‡** çš„ **SVD æ­£äº¤å­ç©ºé—´åˆ†è§£** æ€æƒ³å¼•å…¥ ForgeLens çš„ Stage 1 è®­ç»ƒï¼Œé€šè¿‡å¼ºåˆ¶ WSGM æ¨¡å—å­¦ä¹ ä¸ CLIP è¯­ä¹‰ç‰¹å¾æ­£äº¤çš„ä¼ªé€ ç—•è¿¹ï¼Œæå‡æ£€æµ‹æ€§èƒ½ã€‚

**ä¿®æ”¹æ—¶é—´**: 2026å¹´1æœˆ
**æ ¸å¿ƒæ€æƒ³**: å°†ç‰¹å¾ç©ºé—´åˆ†è§£ä¸ºè¯­ä¹‰å­ç©ºé—´ï¼ˆSemantic Subspaceï¼‰å’Œä¼ªé€ å­ç©ºé—´ï¼ˆForgery Subspaceï¼‰ï¼Œè¿«ä½¿ WSGM åœ¨ä¼ªé€ å­ç©ºé—´ä¸­å­¦ä¹ ã€‚

---

## ğŸ—ï¸ ä¿®æ”¹æ¶æ„

### æ ¸å¿ƒæµç¨‹

```
è¾“å…¥å›¾åƒ â†’ CLIP ViT â†’ å„å±‚ç‰¹å¾
                    â”‚
                    â”œâ”€â”€â†’ åŸå§‹åˆ†ç±»æŸå¤± (CrossEntropy)
                    â”‚
                    â””â”€â”€â†’ SVD æ­£äº¤çº¦æŸ
                         â”‚
                         â”œâ”€â”€â†’ å¯¹å†»ç»“çš„ Attention æƒé‡åš SVD
                         â”œâ”€â”€â†’ æå–å‰ K ä¸ªä¸»æˆåˆ† (è¯­ä¹‰åŸº)
                         â””â”€â”€â†’ è®¡ç®— WSGM è¾“å‡ºåœ¨è¯­ä¹‰å­ç©ºé—´çš„æŠ•å½±

æ€»æŸå¤± = loss_cls + Î» Ã— loss_orth
```

---

## ğŸ“ æ–‡ä»¶ä¿®æ”¹æ¸…å•

### 1. `models/network/clip/model.py` - æ ¸å¿ƒå®ç°

#### æ–°å¢å‚æ•°
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `svd_rank` | 64 | è¯­ä¹‰å­ç©ºé—´ç§©ï¼ˆä¸»æˆåˆ†æ•°é‡ï¼‰|
| `svd_energy_ratio` | 0.9 | SVD èƒ½é‡ä¿ç•™æ¯”ä¾‹ |

#### ä¸»è¦ä¿®æ”¹

**ResidualAttentionBlock** (ç¬¬ 264-289 è¡Œ)
- æ–°å¢ `semantic_proj_matrix` å±æ€§
- æ–°å¢ `return_orth_loss` å‚æ•°
- è®¡ç®— WSGM è¾“å‡ºåœ¨è¯­ä¹‰å­ç©ºé—´çš„æŠ•å½±ä½œä¸ºæ­£äº¤æŸå¤±

```python
def forward(self, x: torch.Tensor, return_orth_loss: bool = False):
    # ... æ ‡å‡†å‰å‘ ...
    if self.use_wsgm and self.wsgm_module is not None:
        wsgm_output = self.wsgm_module(x)
        x = x + wsgm_output

        # è®¡ç®—æ­£äº¤æŸå¤±
        if return_orth_loss and self.semantic_proj_matrix is not None:
            wsgm_flat = wsgm_output.permute(1, 0, 2).reshape(-1, d_model)
            proj = torch.matmul(wsgm_flat, self.semantic_proj_matrix)
            orth_loss = torch.mean(proj ** 2).detach()
```

**Transformer** (ç¬¬ 330-387 è¡Œ)
- æ–°å¢ `_compute_semantic_projection_matrix()` æ–¹æ³•
- å¯¹å†»ç»“çš„ Attention æƒé‡è¿›è¡Œ SVD åˆ†è§£
- è®¡ç®—ç´¯ç§¯èƒ½é‡ï¼Œç¡®å®šè¯­ä¹‰å­ç©ºé—´ç§©

```python
def _compute_semantic_projection_matrix(self) -> torch.Tensor:
    """è®¡ç®—è¯­ä¹‰æŠ•å½±çŸ©é˜µ"""
    # æ”¶é›†æ‰€æœ‰å±‚çš„ in_proj_weight
    all_weights = [block.attn.in_proj_weight for block in self.resblocks]
    combined_weights = torch.cat(all_weights, dim=0)

    # SVD åˆ†è§£
    U, S, Vh = torch.linalg.svd(combined_weights, full_matrices=False)
    V = Vh.T

    # æŒ‰èƒ½é‡æ¯”ä¾‹ç¡®å®šç§©
    cumulative_energy = torch.cumsum(S ** 2, dim=0) / torch.sum(S ** 2)
    rank_by_energy = torch.searchsorted(cumulative_energy, self.svd_energy_ratio) + 1
    rank = min(self.svd_rank, rank_by_energy, V.size(1))

    return V[:, :rank].float()  # [d_model, rank]
```

**VisionTransformer & CLIP**
- æ–°å¢ `return_orth_loss` å‚æ•°ä¼ é€’
- æ”¯æŒå¯é€‰è¿”å›æ­£äº¤æŸå¤±

---

### 2. `models/network/net_stage1.py` - æ¨¡å‹æ¥å£

**ä¿®æ”¹ä½ç½®**: ç¬¬ 33-46 è¡Œ

```python
def forward(self, x, return_rcs=False, return_orth_loss: bool = False):
    if return_rcs:
        feature, cls_tokens, rcs_token = self.backbone.encode_image(x, return_rcs=True)
        result = self.fc(feature)
        return result, cls_tokens, rcs_token
    else:
        if return_orth_loss:
            feature, cls_tokens, orth_loss = self.backbone.encode_image(x, return_orth_loss=True)
            result = self.fc(feature)
            return result, cls_tokens, orth_loss
        else:
            feature, cls_tokens = self.backbone.encode_image(x, return_rcs=False)
            result = self.fc(feature)
            return result, cls_tokens
```

---

### 3. `models/trainer_stage1.py` - è®­ç»ƒé›†æˆ

**æ–°å¢é…ç½®** (ç¬¬ 31-33 è¡Œ)
```python
self.orth_lambda = getattr(opt, 'orth_lambda', 0.1)  # æ­£äº¤æŸå¤±æƒé‡
print(f"[SVD Orthogonal Loss] Lambda coefficient: {self.orth_lambda}")
```

**è®­ç»ƒå¾ªç¯** (ç¬¬ 47-59 è¡Œ)
```python
with autocast():
    output, _, orth_loss = self.model(data, return_orth_loss=True)

    # åˆ†ç±»æŸå¤±
    loss_cls = criterion(output.squeeze(1), target.type(torch.float32))

    # æ€»æŸå¤±
    if orth_loss is not None:
        loss = loss_cls + self.orth_lambda * orth_loss
    else:
        loss = loss_cls
```

**éªŒè¯å¾ªç¯** (ç¬¬ 76-116 è¡Œ)
- é¢å¤–è®°å½• `running_orth_loss`
- TensorBoard æ–°å¢ `Loss_Orth/Validation` æ—¥å¿—

---

### 4. `options/options.py` - å‘½ä»¤è¡Œå‚æ•°

**æ–°å¢å‚æ•°** (ç¬¬ 28-34 è¡Œ)
```python
# SVD Orthogonal Constraint (Effort paper)
parser.add_argument('--orth_lambda', type=float, default=0.1,
                    help='Weight for SVD orthogonal loss in Stage 1')
parser.add_argument('--svd_rank', type=int, default=64,
                    help='Rank of semantic subspace (number of principal components)')
parser.add_argument('--svd_energy_ratio', type=float, default=0.9,
                    help='Energy ratio for SVD rank selection (0-1)')
```

---

### 5. `prepare_small_dataset.py` - æ•°æ®é›†å‡†å¤‡

**ä¿®æ”¹å†…å®¹**: æ”¹ä¸ºæŒ‰æ¯”ä¾‹é‡‡æ ·

| ä¿®æ”¹å‰ | ä¿®æ”¹å |
|--------|--------|
| `samples_per_class=100` | `percentage=0.01` |
| å›ºå®šæ•°é‡ | æŒ‰ç™¾åˆ†æ¯”è‡ªåŠ¨è®¡ç®— |

```python
# 1% æ•°æ®
setup_small_dataset(percentage=0.01)

# 10% æ•°æ®
setup_small_dataset(percentage=0.1)

# 20% æ•°æ®
setup_small_dataset(percentage=0.2)
```

---

## ğŸ¯ å…³é”®è®¾è®¡å†³ç­–

### 1. ä¿æŠ¤ RCS Token

- `manual_attn()` æ–¹æ³•å®Œå…¨ä¿ç•™
- Stage 2 è¯„ä¼°æ—¶ä¸éœ€è¦æ­£äº¤æŸå¤±
- é€šè¿‡ `return_orth_loss` å‚æ•°æ§åˆ¶æ˜¯å¦è®¡ç®—æ­£äº¤æŸå¤±

### 2. æ•ˆç‡ä¼˜åŒ–

- **SVD åªè®¡ç®—ä¸€æ¬¡**: åœ¨ `Transformer.__init__` ä¸­å®Œæˆ
- **æ¢¯åº¦åˆ†ç¦»**: ä½¿ç”¨ `.detach()` ç¡®ä¿æ­£äº¤æŸå¤±ä¸å½±å“ä¸»è®¡ç®—å›¾
- **è®¾å¤‡å¤„ç†**: åŠ¨æ€å°† `semantic_proj_matrix` ç§»åˆ°æ­£ç¡®è®¾å¤‡

### 3. æ•°å­¦åŸç†

æ ¹æ® Effort è®ºæ–‡ï¼š
- å†»ç»“çš„ CLIP Attention æƒé‡ä¸»æˆåˆ†æ–¹å‘ â†’ è¯­ä¹‰å­ç©ºé—´
- WSGM è¾“å‡ºåœ¨è¿™äº›æ–¹å‘ä¸Šçš„æŠ•å½± â†’ åº”è¯¥æœ€å°åŒ–
- æœ€å°åŒ–æŠ•å½± = å¼ºåˆ¶ WSGM å­¦ä¹ ä¸è¯­ä¹‰æ­£äº¤çš„ç‰¹å¾ = æŒ–æ˜ä¼ªé€ ç»†èŠ‚

---

## ğŸ“Š å®éªŒå‚æ•°

### é»˜è®¤è¶…å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `orth_lambda` | 0.1 | æ­£äº¤æŸå¤±æƒé‡ |
| `svd_rank` | 64 | è¯­ä¹‰å­ç©ºé—´ç§© |
| `svd_energy_ratio` | 0.9 | ä¿ç•™ 90% èƒ½é‡ |

### æ•°æ®é›†æ¯”ä¾‹ (è®ºæ–‡è®¾ç½®)

| æ¯”ä¾‹ | æ ·æœ¬æ•° (4ç±») | ç”¨é€” |
|------|-------------|------|
| 1% | ~1,440 | å¿«é€ŸéªŒè¯ |
| 10% | ~14,400 | æ¶ˆèå®éªŒ |
| 20% | ~28,800 | ä¸­ç­‰è§„æ¨¡ |
| 50% | ~72,000 | å®Œæ•´è®­ç»ƒ |
| 100% | ~144,000 | å…¨é‡æ•°æ® |

---

## âœ… å…¼å®¹æ€§

| åŠŸèƒ½ | çŠ¶æ€ |
|------|------|
| RCS Token æå– | âœ… æ­£å¸¸ |
| Stage 1 è®­ç»ƒ | âœ… æ­£å¸¸ |
| Stage 2 è®­ç»ƒ | âœ… æ­£å¸¸ |
| æ¨¡å‹è¯„ä¼° | âœ… æ­£å¸¸ |
| æ–­ç‚¹ç»­è®­ | âœ… å…¼å®¹ |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹ (1% æ•°æ®)

```bash
# 1. å‡†å¤‡æ•°æ®é›†
python prepare_small_dataset.py

# 2. è®­ç»ƒ (å« SVD æ­£äº¤çº¦æŸ)
bash train_setting_1.sh
```

### è‡ªå®šä¹‰å‚æ•°

```bash
# è°ƒæ•´æ­£äº¤æŸå¤±æƒé‡
python train.py --orth_lambda 0.05 --orth_lambda 0.2

# è°ƒæ•´ SVD ç§©
python train.py --svd_rank 32 --svd_energy_ratio 0.95
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

1. **é˜²æ­¢ç‰¹å¾å†—ä½™**: WSGM ä¸ä¼šé‡å¤å­¦ä¹  CLIP å·²æœ‰çš„è¯­ä¹‰ç‰¹å¾
2. **ä¸“æ³¨ä¼ªé€ ç—•è¿¹**: å¼ºåˆ¶åœ¨è¯­ä¹‰å­ç©ºé—´çš„è¡¥ç©ºé—´ï¼ˆä¼ªé€ å­ç©ºé—´ï¼‰å­¦ä¹ 
3. **æå‡æ³›åŒ–èƒ½åŠ›**: æ›´å¥½æ•æ‰è·¨åŸŸä¼ªé€ ç‰¹å¾

---

## ğŸ”§ åç»­ä¼˜åŒ–æ–¹å‘

1. **è‡ªé€‚åº” Î»**: æ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´ `orth_lambda`
2. **å±‚çº§åˆ«æƒé‡**: ä¸åŒå±‚ä½¿ç”¨ä¸åŒçš„æ­£äº¤çº¦æŸå¼ºåº¦
3. **å¤šå°ºåº¦æ­£äº¤**: åœ¨ä¸åŒç‰¹å¾ç²’åº¦ä¸Šåº”ç”¨æ­£äº¤çº¦æŸ

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026å¹´1æœˆ
