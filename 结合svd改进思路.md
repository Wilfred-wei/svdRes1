
# ForgeLens SVD-Orthogonal å¢å¼ºå®æ–½æŒ‡å— (Stage 1)

## ğŸ“„ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£æ—¨åœ¨æŒ‡å¯¼å¦‚ä½•åœ¨ **ForgeLens Stage 1 (WSGM è®­ç»ƒé˜¶æ®µ)** ä¸­å¼•å…¥åŸºäº **Effort (Orthogonal Subspace Decomposition)** çš„ SVD æ­£äº¤çº¦æŸæœºåˆ¶ã€‚
**æ ¸å¿ƒç›®æ ‡**ï¼šé€šè¿‡æ•°å­¦çº¦æŸï¼Œå¼ºåˆ¶ WSGM å­¦ä¹ ä¸ CLIP é¢„è®­ç»ƒè¯­ä¹‰ç‰¹å¾ï¼ˆSemantic Subspaceï¼‰**æ­£äº¤**çš„æ®‹å·®ç‰¹å¾ï¼ˆForgery Subspaceï¼‰ï¼Œä»è€Œé¿å…è¯­ä¹‰é‡å¤å­¦ä¹ ï¼Œæå‡å¯¹ä¼ªé€ ç—•è¿¹çš„æ•è·èƒ½åŠ›ã€‚

> âš ï¸ **é‡è¦è­¦å‘Š**ï¼šæœ¬é¡¹ç›®å·²åŒ…å« Stage 2 çš„ RCS (Residual Context Structure) å¢å¼ºã€‚åœ¨ä¿®æ”¹åº•å±‚ä»£ç æ—¶ï¼Œ**å¿…é¡»ç¡®ä¿ `manual_attn` ç­‰æœåŠ¡äº RCS çš„æ¥å£ä¸è¢«ç ´å**ã€‚

---

## ğŸ›  ä¿®æ”¹æ¸…å•ä¸å®æ–½ç»†èŠ‚

### 1. ä¿®æ”¹ `models/network/clip/model.py`

è¿™æ˜¯æ ¸å¿ƒä¿®æ”¹ç‚¹ã€‚æˆ‘ä»¬éœ€è¦åœ¨ `ResidualAttentionBlock` ä¸­â€œåŸ‹å…¥â€SVD æŠ•å½±çŸ©é˜µï¼Œå¹¶åœ¨å‰å‘ä¼ æ’­æ—¶è®¡ç®—æ­£äº¤æŸå¤±ã€‚

#### 1.1 æ–°å¢ï¼šSVD åˆå§‹åŒ–æ–¹æ³• (`init_svd_projection`)

åœ¨ `ResidualAttentionBlock` ç±»ä¸­æ·»åŠ æ­¤æ–¹æ³•ã€‚å®ƒåªåº”åœ¨ Stage 1 å¼€å§‹å‰è¢«è°ƒç”¨ä¸€æ¬¡ã€‚

```python
    def init_svd_projection(self, energy_threshold=0.90):
        """
        [SVD-Orthogonal Action]
        å¯¹ Self-Attention çš„è¾“å…¥æŠ•å½±æƒé‡è¿›è¡Œ SVD åˆ†è§£ï¼Œæ„å»ºè¯­ä¹‰æŠ•å½±çŸ©é˜µã€‚
        è¯¥çŸ©é˜µä½œä¸º Buffer æ³¨å†Œï¼Œä¸å‚ä¸æ¢¯åº¦æ›´æ–°ã€‚
        """
        # 1. è·å– Attention çš„æŠ•å½±æƒé‡ (Q, K, V combined)
        # æ³¨æ„: CLIP çš„ MultiheadAttention é€šå¸¸ä½¿ç”¨ in_proj_weight
        weight = self.attn.in_proj_weight.detach() 
        
        # 2. æ‰§è¡Œ SVD åˆ†è§£
        # U: (D_out, D_out), S: (min_D,), V: (D_in, D_in)
        # è¿™æ˜¯ä¸€ä¸ªè®¡ç®—å¯†é›†å‹æ“ä½œï¼Œä»…éœ€è¿è¡Œä¸€æ¬¡
        try:
            U, S, V = torch.linalg.svd(weight, full_matrices=False)
        except:
            # å…¼å®¹æ—§ç‰ˆ PyTorch
            U, S, V = torch.svd(weight)

        # 3. ç¡®å®šä¿ç•™çš„ä¸»æˆåˆ†æ•°é‡ (Top-K)
        # åŸºäºèƒ½é‡å æ¯” (Energy Ratio)
        energy = torch.cumsum(S ** 2, dim=0) / torch.sum(S ** 2)
        k = torch.searchsorted(energy, energy_threshold).item() + 1
        # æˆ–è€…è®¾ç½®ä¸€ä¸ªç¡¬é˜ˆå€¼ï¼Œä¾‹å¦‚ k = min(k, 160)
        
        # 4. æ„å»ºè¯­ä¹‰æŠ•å½±çŸ©é˜µ P_sem = U_k * U_k^T
        # Shape: (D_model, D_model)
        U_k = U[:, :k]
        P_sem = torch.mm(U_k, U_k.t())
        
        # 5. æ³¨å†Œä¸º Buffer (Persistent=False è¡¨ç¤ºå¯èƒ½ä¸éœ€è¦å­˜å…¥ state_dictï¼Œè§†éœ€æ±‚è€Œå®š)
        self.register_buffer('sem_proj', P_sem)
        print(f"Initialized SVD Projection: Kept {k} components ({energy_threshold*100}%)")

```

#### 1.2 ä¿®æ”¹ï¼šForward å‡½æ•° (`forward`)

æˆ‘ä»¬éœ€è¦åœ¨ä¸å¹²æ‰° RCS é€»è¾‘ (`manual_attn`) çš„å‰æä¸‹ï¼Œè®¡ç®— WSGM è¾“å‡ºçš„æ­£äº¤æ€§ã€‚

```python
    # ä¿®æ”¹ forward å‡½æ•°ç­¾åï¼Œå¢åŠ  return_orth_loss å‚æ•°
    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor = None, return_orth_loss: bool = False):
        # --- åŸæœ‰é€»è¾‘ (RCS ä¾èµ–æ­¤éƒ¨åˆ†ï¼Œå‹¿åŠ¨) ---
        # self.attn(...) ç­‰æ ‡å‡†æµç¨‹
        # ...
        
        # --- WSGM é€»è¾‘ (ForgeLens æ’å…¥ç‚¹) ---
        # å‡è®¾ WSGM å·²ç»æ³¨å…¥åˆ° Block ä¸­ï¼Œé€šå¸¸åä¸º self.wsgm æˆ–ç±»ä¼¼
        # åŸå§‹: x = x + self.wsgm(x_ln) 
        
        # è·å– WSGM çš„çº¯ç‰¹å¾è¾“å‡º (ä¸åŠ æ®‹å·®å‰)
        wsgm_output = self.wsgm(self.ln_1(x)) # æˆ–è€…æ˜¯ wsgm å†…éƒ¨è®¡ç®—å‡ºçš„ç‰¹å¾
        
        # --- æ–°å¢: æ­£äº¤æŸå¤±è®¡ç®— ---
        orth_loss = None
        if return_orth_loss and hasattr(self, 'sem_proj'):
            # è®¡ç®— WSGM ç‰¹å¾åœ¨è¯­ä¹‰ç©ºé—´ä¸Šçš„æŠ•å½±
            # wsgm_output: [Batch, Seq, Dim]
            # sem_proj:    [Dim, Dim]
            # project:     [Batch, Seq, Dim]
            projection = torch.matmul(wsgm_output, self.sem_proj)
            
            # æˆ‘ä»¬å¸Œæœ›æŠ•å½±é‡è¶Šå°è¶Šå¥½ (å³æ­£äº¤)
            # ä½¿ç”¨ L2 èŒƒæ•°çš„å¹³æ–¹ä½œä¸º Loss
            orth_loss = torch.norm(projection, p=2) ** 2 / projection.numel()
        
        # åº”ç”¨ WSGM æ®‹å·®
        x = x + wsgm_output
        
        # MLP éƒ¨åˆ† (ä¿æŒä¸å˜)
        x = x + self.mlp(self.ln_2(x))

        if return_orth_loss:
            return x, orth_loss
        return x

```

---

### 2. ä¿®æ”¹ `models/network/net_stage1.py` (æ¡¥æ¥å±‚)

`NetStage1` é€šå¸¸ä½œä¸º CLIP çš„ Wrapperã€‚æˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œæš´éœ² SVD åˆå§‹åŒ–æ¥å£ï¼Œå¹¶åœ¨ Forward ä¸­èšåˆæ‰€æœ‰å±‚çš„ Lossã€‚

```python
class NetStage1(nn.Module):
    # ... ç°æœ‰ä»£ç  ...

    def init_svd_for_training(self):
        """éå†æ‰€æœ‰ Block å¹¶åˆå§‹åŒ– SVD"""
        print("Initializing SVD constraints for CLIP Blocks...")
        for block in self.image_encoder.transformer.resblocks:
            if hasattr(block, 'init_svd_projection'):
                block.init_svd_projection()
                
    def forward(self, x, return_loss=False):
        # åœ¨è°ƒç”¨ image_encoder æ—¶ï¼Œä¼ é€’ return_orth_loss=True
        # è¿™å¯èƒ½éœ€è¦ä¿®æ”¹ CLIP çš„ forward æˆ–è€…æ‰‹åŠ¨éå† blocks
        
        # å»ºè®®æ–¹æ¡ˆï¼šå¦‚æœ CLIP ä»£ç éš¾ä»¥æ”¹åŠ¨ forward ç­¾åï¼Œ
        # å¯ä»¥ç”¨ hook æˆ–è€…åœ¨ NetStage1 é‡Œæ‰‹åŠ¨å¾ªç¯ resblocks
        
        features = x
        total_orth_loss = 0.0
        
        # æ‰‹åŠ¨æ‰§è¡Œ Transformer å±‚ä»¥æ•è· loss (ä¼ªä»£ç )
        for i, block in enumerate(self.image_encoder.transformer.resblocks):
            if self.training:
                features, loss = block(features, return_orth_loss=True)
                if loss is not None:
                    total_orth_loss += loss
            else:
                features = block(features)
        
        # ... åç»­åˆ†ç±»å¤´é€»è¾‘ ...
        
        if self.training and return_loss:
            return logits, total_orth_loss
        return logits

```

---

### 3. ä¿®æ”¹ `models/trainer_stage1.py` (è®­ç»ƒå¾ªç¯)

æœ€åï¼Œå°† Loss æ•´åˆåˆ°ä¼˜åŒ–æ­¥éª¤ä¸­ã€‚

```python
    # åœ¨ Trainer åˆå§‹åŒ–æˆ–è®­ç»ƒå¼€å§‹å‰è°ƒç”¨
    def before_train_loop(self):
        # ç¡®ä¿åªè®¡ç®—ä¸€æ¬¡ SVD
        self.model.init_svd_for_training()

    def train_step(self, batch):
        # ... æ•°æ®åŠ è½½ ...
        
        # Forward
        logits, orth_loss_sum = self.model(images, return_loss=True)
        
        # è®¡ç®—åŸæœ¬çš„åˆ†ç±» Loss
        loss_cls = self.criterion(logits, labels)
        
        # è®¡ç®—æ€» Loss
        # å»ºè®® lambda ç³»æ•°: 0.1 ~ 0.01
        lambda_orth = 0.05 
        
        # å¦‚æœ orth_loss_sum æ˜¯æ‰€æœ‰å±‚çš„å’Œï¼Œå¯èƒ½éœ€è¦é™¤ä»¥å±‚æ•°åšå½’ä¸€åŒ–
        num_layers = len(self.model.image_encoder.transformer.resblocks)
        avg_orth_loss = orth_loss_sum / num_layers
        
        total_loss = loss_cls + lambda_orth * avg_orth_loss
        
        # Backward
        self.optimizer.zero_grad()
        total_loss.backward()
        self.optimizer.step()
        
        # Logging
        # è®°å½• loss_orth ä»¥ä¾¿è§‚å¯Ÿæ”¶æ•›æƒ…å†µ

```

---

## ğŸ” éªŒè¯ä¸æ£€æŸ¥ç‚¹ (Checklist)

åœ¨ä»£ç ä¿®æ”¹å®Œæˆåï¼Œè¯·è¿›è¡Œä»¥ä¸‹æ£€æŸ¥ä»¥ç¡®ä¿â€œæ— ä¾µå…¥â€åŸåˆ™å¾—åˆ°éµå®ˆï¼š

1. **Stage 2 å…¼å®¹æ€§æ£€æŸ¥**ï¼š
* è¿è¡Œ `evaluate.sh` (åŸºäº Stage 2 RCS)ã€‚
* ç¡®ä¿ä»£ç ä¸ä¼šæŠ¥é”™ï¼ˆå› ä¸º Stage 2 è¿è¡Œæ—¶ `return_orth_loss` é»˜è®¤ä¸º `False`ï¼Œä¸” SVD buffer å³ä½¿å­˜åœ¨ä¹Ÿä¸ä¼šè¢«ä½¿ç”¨ï¼‰ã€‚
* **é¢„æœŸ**ï¼šStage 2 çš„æ¨ç†ç»“æœåº”ä¸ä¿®æ”¹å‰å®Œå…¨ä¸€è‡´ï¼ˆ0 error deviationï¼‰ã€‚


2. **SVD ç¼“å­˜æ£€æŸ¥**ï¼š
* åœ¨è®­ç»ƒå¯åŠ¨æ—¥å¿—ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦è¾“å‡ºäº† `"Initialized SVD Projection..."`ã€‚
* ç¡®ä¿è¯¥æ—¥å¿—åªåœ¨ç¨‹åºå¯åŠ¨æ—¶å‡ºç°ä¸€æ¬¡ï¼Œè€Œä¸æ˜¯æ¯ä¸ª Batch éƒ½å‡ºç°ã€‚


3. **Loss è§‚å¯Ÿ**ï¼š
* ä½¿ç”¨ TensorBoard æˆ–æ—¥å¿—è§‚å¯Ÿ `loss_orth`ã€‚
* å®ƒåº”è¯¥éšç€è®­ç»ƒé€æ¸ä¸‹é™ï¼Œè¿™è¡¨æ˜ WSGM æ­£åœ¨å­¦ç€â€œé¿å¼€â€CLIP çš„ä¸»æˆåˆ†æ–¹å‘ï¼Œå‘æ®‹å·®ç©ºé—´è¿ç§»ã€‚